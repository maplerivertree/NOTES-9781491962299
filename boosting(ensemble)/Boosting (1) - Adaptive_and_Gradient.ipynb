{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortcoming: <br>\n",
    "Ada (Adaptive Boosting) abd Gradient Boosting is sequential <br>\n",
    "it cannot be parallelized <br>\n",
    "one predictor only acts after the preivous one is done and evaulated<br>\n",
    "thus, Ada does not scale well<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada_Intuition: <br>\n",
    "After one predictor learned and is evaluated, <br>\n",
    "The mislabelled/predicted instances areplaced with higher weights<br>\n",
    "So the subsequent learner can focus on them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, this should be manually built out using the above logic <br>\n",
    "Sklearn also has a built-in clf <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth = 1), n_estimators =200, \n",
    "    algorithm= \"SAMME,R\", learning_rate = 0.01)\n",
    "ada_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient_Intuition: <br>\n",
    "Gradient Boosting works by fitting subsequent predictors to the <br>\n",
    "residual erros made by the previous predictor <br>\n",
    "as y_pred1 is 5, y_actual is 7, <br>\n",
    "then y_actual_2 should be 2, <br>\n",
    "if y_pred2 = 3, <br>\n",
    "then y_actual_3 should be -1 <br>\n",
    "\n",
    "Walkthrough example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth = 2)\n",
    "tree_reg1.fit(X, y)\n",
    "\n",
    "y2 = y - tree_reg1.pred(X)\n",
    "\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth = 2)\n",
    "tree_reg2.fit(X, y2)\n",
    "\n",
    "y3 = y2 - tree_reg2.pred(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth =2)\n",
    "tree_reg3.fit(X, y3)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_boosted = sum(learner.predict(X_test) for learner in (tree_reg1, tree_reg2, tree_reg3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above is equivalent to the sklearn built-in below\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimator = 3)\n",
    "gbrt.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
